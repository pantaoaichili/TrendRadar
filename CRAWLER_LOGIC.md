# TrendRadar æ–°é—»çƒ­ç‚¹çˆ¬å–é€»è¾‘è¯¦è§£

## ğŸ“‹ ç›®å½•

- [æ•´ä½“æ¶æ„](#æ•´ä½“æ¶æ„)
- [æ•°æ®è·å–æµç¨‹](#æ•°æ®è·å–æµç¨‹)
- [æ•°æ®å¤„ç†æµç¨‹](#æ•°æ®å¤„ç†æµç¨‹)
- [å…³é”®è¯åŒ¹é…é€»è¾‘](#å…³é”®è¯åŒ¹é…é€»è¾‘)
- [æƒé‡è®¡ç®—ç®—æ³•](#æƒé‡è®¡ç®—ç®—æ³•)
- [æ¨é€æ¨¡å¼é€»è¾‘](#æ¨é€æ¨¡å¼é€»è¾‘)
- [æ•°æ®å­˜å‚¨æœºåˆ¶](#æ•°æ®å­˜å‚¨æœºåˆ¶)

---

## ğŸ—ï¸ æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GitHub Actions å®šæ—¶è§¦å‘                    â”‚
â”‚                  (æˆ–æ‰‹åŠ¨è§¦å‘ workflow_dispatch)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NewsAnalyzer.run()                        â”‚
â”‚                   ä¸»åˆ†æå™¨å…¥å£                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                             â”‚
        â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ _crawl_data() â”‚          â”‚ åŠ è½½é…ç½®æ–‡ä»¶      â”‚
â”‚ æ•°æ®çˆ¬å–       â”‚          â”‚ æ£€æŸ¥é…ç½®          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DataFetcher.crawl_websites()                  â”‚
â”‚              éå†æ‰€æœ‰å¹³å°ï¼Œè·å–çƒ­ç‚¹æ•°æ®                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                             â”‚
        â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ä¿å­˜åŸå§‹æ•°æ®   â”‚          â”‚ å…³é”®è¯åŒ¹é…       â”‚
â”‚ åˆ°æ–‡ä»¶        â”‚          â”‚ æƒé‡è®¡ç®—         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          _execute_mode_strategy()                           â”‚
â”‚          æ ¹æ®æ¨é€æ¨¡å¼æ‰§è¡Œä¸åŒé€»è¾‘                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                             â”‚
        â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç”ŸæˆæŠ¥å‘Š      â”‚          â”‚ å‘é€é€šçŸ¥          â”‚
â”‚ (HTML/TXT)    â”‚          â”‚ (é’‰é’‰/é£ä¹¦ç­‰)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ æ•°æ®è·å–æµç¨‹

### 1. æ•°æ®æº

**API åœ°å€**ï¼š`https://newsnow.busiyi.world/api/s?id={platform_id}&latest`

**æ•°æ®æ¥æº**ï¼šåŸºäº [newsnow](https://github.com/ourongxing/newsnow) é¡¹ç›®æä¾›çš„ç»Ÿä¸€ API

**æ”¯æŒçš„å¹³å°**ï¼ˆåœ¨ `config/config.yaml` ä¸­é…ç½®ï¼‰ï¼š
- `zhihu` - çŸ¥ä¹
- `weibo` - å¾®åš
- `douyin` - æŠ–éŸ³
- `bilibili-hot-search` - bilibili çƒ­æœ
- `baidu` - ç™¾åº¦çƒ­æœ
- `toutiao` - ä»Šæ—¥å¤´æ¡
- `wallstreetcn-hot` - åå°”è¡—è§é—»
- `thepaper` - æ¾æ¹ƒæ–°é—»
- `ifeng` - å‡¤å‡°ç½‘
- `tieba` - è´´å§
- `cls-hot` - è´¢è”ç¤¾çƒ­é—¨

### 2. æ•°æ®è·å–æµç¨‹

#### æ­¥éª¤ 1: åˆå§‹åŒ– DataFetcher

```python
class DataFetcher:
    def __init__(self, proxy_url: Optional[str] = None):
        self.proxy_url = proxy_url  # å¯é€‰ä»£ç†é…ç½®
```

#### æ­¥éª¤ 2: éå†å¹³å°åˆ—è¡¨

ä» `config/config.yaml` è¯»å–å¹³å°é…ç½®ï¼š

```python
platforms:
  - id: "zhihu"
    name: "çŸ¥ä¹"
  - id: "weibo"
    name: "å¾®åš"
  # ... æ›´å¤šå¹³å°
```

#### æ­¥éª¤ 3: é€ä¸ªè·å–æ•°æ®

å¯¹æ¯ä¸ªå¹³å°è°ƒç”¨ `fetch_data()`ï¼š

```python
def fetch_data(self, id_info, max_retries=2):
    # 1. æ„å»ºè¯·æ±‚ URL
    url = f"https://newsnow.busiyi.world/api/s?id={id_value}&latest"
    
    # 2. è®¾ç½®è¯·æ±‚å¤´ï¼ˆæ¨¡æ‹Ÿæµè§ˆå™¨ï¼‰
    headers = {
        "User-Agent": "Mozilla/5.0 ...",
        "Accept": "application/json",
        # ...
    }
    
    # 3. å‘é€è¯·æ±‚ï¼ˆæ”¯æŒé‡è¯•ï¼‰
    response = requests.get(url, headers=headers, timeout=10)
    
    # 4. è§£æ JSON å“åº”
    data = json.loads(response.text)
    
    # 5. è¿”å›æ•°æ®
    return data_text, id_value, alias
```

**é‡è¯•æœºåˆ¶**ï¼š
- é»˜è®¤æœ€å¤šé‡è¯• 2 æ¬¡
- é‡è¯•é—´éš”ï¼š3-5 ç§’ + é€’å¢å»¶è¿Ÿ
- å¤±è´¥åè®°å½•åˆ° `failed_ids` åˆ—è¡¨

#### æ­¥éª¤ 4: è¯·æ±‚é—´éš”æ§åˆ¶

```python
# é»˜è®¤é—´éš”ï¼š1000 æ¯«ç§’ï¼ˆ1ç§’ï¼‰
request_interval = CONFIG["REQUEST_INTERVAL"]

# å®é™…é—´éš”ï¼šåŸºç¡€é—´éš” + éšæœºæ³¢åŠ¨ï¼ˆ-10ms åˆ° +20msï¼‰
actual_interval = request_interval + random.randint(-10, 20)
actual_interval = max(50, actual_interval)  # æœ€å° 50ms

time.sleep(actual_interval / 1000)
```

**ç›®çš„**ï¼šé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œæ¨¡æ‹Ÿäººç±»è¡Œä¸º

#### æ­¥éª¤ 5: è§£æå“åº”æ•°æ®

API è¿”å›æ ¼å¼ï¼š

```json
{
  "status": "success",
  "items": [
    {
      "title": "æ–°é—»æ ‡é¢˜",
      "url": "PCç«¯é“¾æ¥",
      "mobileUrl": "ç§»åŠ¨ç«¯é“¾æ¥"
    },
    // ... æ›´å¤šæ–°é—»
  ]
}
```

å¤„ç†é€»è¾‘ï¼š

```python
for index, item in enumerate(data.get("items", []), 1):
    title = item.get("title")
    
    # è·³è¿‡æ— æ•ˆæ ‡é¢˜
    if title is None or isinstance(title, float) or not str(title).strip():
        continue
    
    # è®°å½•æ’åå’Œé“¾æ¥
    results[id_value][title] = {
        "ranks": [index],  # æ’ååˆ—è¡¨ï¼ˆå¯èƒ½å¤šæ¬¡å‡ºç°ï¼‰
        "url": url,
        "mobileUrl": mobile_url,
    }
```

**å…³é”®ç‚¹**ï¼š
- æ’åä» 1 å¼€å§‹ï¼ˆ1 = ç¬¬1åï¼Œ2 = ç¬¬2å...ï¼‰
- å¦‚æœåŒä¸€æ ‡é¢˜å¤šæ¬¡å‡ºç°ï¼Œåˆå¹¶æ’ååˆ—è¡¨
- ä¿å­˜ PC å’Œç§»åŠ¨ç«¯é“¾æ¥

---

## ğŸ” æ•°æ®å¤„ç†æµç¨‹

### 1. ä¿å­˜åŸå§‹æ•°æ®

**æ–‡ä»¶è·¯å¾„**ï¼š`output/YYYYå¹´MMæœˆDDæ—¥/txt/HHæ—¶MMåˆ†.txt`

**æ–‡ä»¶æ ¼å¼**ï¼š
```
zhihu | çŸ¥ä¹
1. æ–°é—»æ ‡é¢˜1
2. æ–°é—»æ ‡é¢˜2
...

weibo | å¾®åš
1. æ–°é—»æ ‡é¢˜1
2. æ–°é—»æ ‡é¢˜2
...
```

**ç›®çš„**ï¼š
- ä¿ç•™å†å²æ•°æ®
- æ”¯æŒå¢é‡æ£€æµ‹
- ç”¨äºè¶‹åŠ¿åˆ†æ

### 2. æ–°å¢æ£€æµ‹

**å‡½æ•°**ï¼š`detect_latest_new_titles()`

**é€»è¾‘**ï¼š
1. è¯»å–å½“å¤©æ‰€æœ‰å·²ä¿å­˜çš„æ–‡ä»¶
2. å¯¹æ¯”æœ€æ–°ä¸€æ¬¡çˆ¬å–çš„æ•°æ®
3. æ‰¾å‡ºé¦–æ¬¡å‡ºç°çš„æ–°é—»æ ‡é¢˜
4. æ ‡è®°ä¸º ğŸ†• æ–°å¢æ–°é—»

**å®ç°**ï¼š
```python
def detect_latest_new_titles(current_platform_ids):
    # 1. è¯»å–å½“å¤©æ‰€æœ‰å†å²æ•°æ®
    all_today_titles = read_all_today_titles(current_platform_ids)
    
    # 2. è·å–æœ€æ–°ä¸€æ¬¡çš„æ•°æ®
    latest_file = get_latest_file()
    latest_titles = parse_file(latest_file)
    
    # 3. æ‰¾å‡ºæ–°å¢æ ‡é¢˜
    new_titles = {}
    for platform_id, titles in latest_titles.items():
        historical_titles = all_today_titles.get(platform_id, {})
        new_list = [
            title for title in titles.keys()
            if title not in historical_titles
        ]
        if new_list:
            new_titles[platform_id] = new_list
    
    return new_titles
```

---

## ğŸ¯ å…³é”®è¯åŒ¹é…é€»è¾‘

### 1. å…³é”®è¯åŠ è½½

**æ–‡ä»¶**ï¼š`config/frequency_words.txt`

**å‡½æ•°**ï¼š`load_frequency_words()`

**è§£æè§„åˆ™**ï¼š

```python
def load_frequency_words():
    word_groups = []  # è¯ç»„åˆ—è¡¨
    filter_words = []  # è¿‡æ»¤è¯åˆ—è¡¨
    
    current_group = {
        "normal": [],      # æ™®é€šè¯
        "required": [],    # å¿…é¡»è¯ï¼ˆ+å¼€å¤´ï¼‰
    }
    
    for line in file:
        line = line.strip()
        
        if not line:  # ç©ºè¡Œ = æ–°è¯ç»„
            if current_group["normal"] or current_group["required"]:
                word_groups.append(current_group)
                current_group = {"normal": [], "required": []}
        
        elif line.startswith("!"):  # è¿‡æ»¤è¯
            filter_words.append(line[1:])
        
        elif line.startswith("+"):  # å¿…é¡»è¯
            current_group["required"].append(line[1:])
        
        else:  # æ™®é€šè¯
            current_group["normal"].append(line)
```

**ç¤ºä¾‹é…ç½®**ï¼š
```txt
åä¸º
OPPO
+å‘å¸ƒ

Aè‚¡
ä¸Šè¯
+æ¶¨è·Œ
!é¢„æµ‹
```

**è§£æç»“æœ**ï¼š
```python
word_groups = [
    {
        "normal": ["åä¸º", "OPPO"],
        "required": ["å‘å¸ƒ"]
    },
    {
        "normal": ["Aè‚¡", "ä¸Šè¯"],
        "required": ["æ¶¨è·Œ"],
        "filter": ["é¢„æµ‹"]  # å…¨å±€è¿‡æ»¤è¯
    }
]
```

### 2. åŒ¹é…é€»è¾‘

**å‡½æ•°**ï¼š`matches_word_groups()`

**åŒ¹é…è§„åˆ™**ï¼š

```python
def matches_word_groups(title, word_groups, filter_words):
    # 1. ç±»å‹æ£€æŸ¥
    if not isinstance(title, str) or not title.strip():
        return False
    
    # 2. å¦‚æœæ²¡æœ‰é…ç½®è¯ç»„ï¼ŒåŒ¹é…æ‰€æœ‰ï¼ˆæ˜¾ç¤ºå…¨éƒ¨æ–°é—»ï¼‰
    if not word_groups:
        return True
    
    title_lower = title.lower()
    
    # 3. è¿‡æ»¤è¯æ£€æŸ¥ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
    for filter_word in filter_words:
        if filter_word.lower() in title_lower:
            return False  # åŒ…å«è¿‡æ»¤è¯ï¼Œç›´æ¥æ’é™¤
    
    # 4. è¯ç»„åŒ¹é…ï¼ˆåªè¦åŒ¹é…ä¸€ä¸ªè¯ç»„å³å¯ï¼‰
    for group in word_groups:
        required_words = group["required"]
        normal_words = group["normal"]
        
        # 4.1 å¿…é¡»è¯æ£€æŸ¥ï¼ˆå¦‚æœé…ç½®äº†å¿…é¡»è¯ï¼‰
        if required_words:
            all_required_present = all(
                req_word.lower() in title_lower 
                for req_word in required_words
            )
            if not all_required_present:
                continue  # ç¼ºå°‘å¿…é¡»è¯ï¼Œè·³è¿‡è¿™ä¸ªè¯ç»„
        
        # 4.2 æ™®é€šè¯æ£€æŸ¥
        if normal_words:
            any_normal_present = any(
                normal_word.lower() in title_lower 
                for normal_word in normal_words
            )
            if not any_normal_present:
                continue  # æ²¡æœ‰æ™®é€šè¯ï¼Œè·³è¿‡è¿™ä¸ªè¯ç»„
        
        # 4.3 åŒ¹é…æˆåŠŸ
        return True
    
    # 5. æ‰€æœ‰è¯ç»„éƒ½ä¸åŒ¹é…
    return False
```

**åŒ¹é…ç¤ºä¾‹**ï¼š

| æ ‡é¢˜ | å…³é”®è¯é…ç½® | åŒ¹é…ç»“æœ | åŸå›  |
|------|-----------|---------|------|
| "åä¸ºMate60æ­£å¼å‘å¸ƒ" | åä¸º +å‘å¸ƒ | âœ… åŒ¹é… | åŒ…å«"åä¸º"å’Œ"å‘å¸ƒ" |
| "åä¸ºé”€é‡åˆ›æ–°é«˜" | åä¸º +å‘å¸ƒ | âŒ ä¸åŒ¹é… | ç¼ºå°‘"å‘å¸ƒ" |
| "è‹¹æœiPhone15å‘å¸ƒ" | åä¸º +å‘å¸ƒ | âŒ ä¸åŒ¹é… | ç¼ºå°‘"åä¸º" |
| "ä¸“å®¶é¢„æµ‹Aè‚¡æ¶¨è·Œ" | Aè‚¡ +æ¶¨è·Œ !é¢„æµ‹ | âŒ ä¸åŒ¹é… | åŒ…å«è¿‡æ»¤è¯"é¢„æµ‹" |
| "Aè‚¡ä»Šæ—¥å¤§å¹…æ¶¨è·Œ" | Aè‚¡ +æ¶¨è·Œ !é¢„æµ‹ | âœ… åŒ¹é… | åŒ…å«"Aè‚¡"å’Œ"æ¶¨è·Œ"ï¼Œä¸”ä¸åŒ…å«"é¢„æµ‹" |

### 3. è¯ç»„ç»Ÿè®¡

**å‡½æ•°**ï¼š`count_word_frequency()`

**ç»Ÿè®¡é€»è¾‘**ï¼š

```python
# éå†æ‰€æœ‰æ–°é—»
for platform_id, titles in results.items():
    for title, title_data in titles.items():
        # æ£€æŸ¥æ˜¯å¦åŒ¹é…å…³é”®è¯
        if matches_word_groups(title, word_groups, filter_words):
            # æ‰¾åˆ°åŒ¹é…çš„è¯ç»„
            matched_group = find_matched_group(title, word_groups)
            
            # ç»Ÿè®¡åˆ°å¯¹åº”è¯ç»„
            word_stats[matched_group]["count"] += 1
            word_stats[matched_group]["titles"][platform_id].append({
                "title": title,
                "ranks": title_data["ranks"],
                "url": title_data.get("url"),
                "count": len(title_data["ranks"]),
            })
```

**ç»“æœç»“æ„**ï¼š
```python
word_stats = {
    "AI ChatGPT": {
        "count": 5,  # åŒ¹é…çš„æ–°é—»æ•°é‡
        "titles": {
            "zhihu": [æ–°é—»1, æ–°é—»2],
            "weibo": [æ–°é—»3],
            # ...
        }
    },
    "æ¯”äºšè¿ª ç‰¹æ–¯æ‹‰": {
        "count": 3,
        "titles": {...}
    }
}
```

---

## âš–ï¸ æƒé‡è®¡ç®—ç®—æ³•

### 1. æƒé‡ç»„æˆ

**å‡½æ•°**ï¼š`calculate_news_weight()`

**ä¸‰ä¸ªç»´åº¦**ï¼š

| ç»´åº¦ | æƒé‡ | è¯´æ˜ |
|------|------|------|
| **æ’åæƒé‡** | 60% | æ–°é—»åœ¨æ¦œå•ä¸­çš„æ’åä½ç½® |
| **é¢‘æ¬¡æƒé‡** | 30% | æ–°é—»å‡ºç°çš„æ¬¡æ•°ï¼ˆæŒç»­æ€§ï¼‰ |
| **çƒ­åº¦æƒé‡** | 10% | é«˜æ’åå‡ºç°çš„æ¯”ä¾‹ |

### 2. è®¡ç®—å…¬å¼

```python
def calculate_news_weight(title_data, rank_threshold=5):
    ranks = title_data.get("ranks", [])  # æ’ååˆ—è¡¨
    count = len(ranks)  # å‡ºç°æ¬¡æ•°
    
    # 1. æ’åæƒé‡ï¼šÎ£(11 - min(rank, 10)) / å‡ºç°æ¬¡æ•°
    rank_scores = []
    for rank in ranks:
        score = 11 - min(rank, 10)  # ç¬¬1å=10åˆ†ï¼Œç¬¬2å=9åˆ†...ç¬¬10å=1åˆ†ï¼Œç¬¬11ååŠä»¥å=1åˆ†
        rank_scores.append(score)
    rank_weight = sum(rank_scores) / len(ranks) if ranks else 0
    
    # 2. é¢‘æ¬¡æƒé‡ï¼šmin(å‡ºç°æ¬¡æ•°, 10) Ã— 10
    frequency_weight = min(count, 10) * 10  # æœ€å¤š100åˆ†
    
    # 3. çƒ­åº¦æƒé‡ï¼šé«˜æ’åæ¬¡æ•° / æ€»å‡ºç°æ¬¡æ•° Ã— 100
    high_rank_count = sum(1 for rank in ranks if rank <= rank_threshold)
    hotness_ratio = high_rank_count / len(ranks) if ranks else 0
    hotness_weight = hotness_ratio * 100  # 0-100åˆ†
    
    # 4. ç»¼åˆæƒé‡
    total_weight = (
        rank_weight * 0.6 +      # 60%
        frequency_weight * 0.3 +  # 30%
        hotness_weight * 0.1      # 10%
    )
    
    return total_weight
```

### 3. è®¡ç®—ç¤ºä¾‹

**ç¤ºä¾‹ 1ï¼šé«˜æ’åæ–°é—»**

```python
title_data = {
    "ranks": [1, 2, 1],  # ç¬¬1åå‡ºç°2æ¬¡ï¼Œç¬¬2åå‡ºç°1æ¬¡
    "count": 3
}

# æ’åæƒé‡ï¼š(10 + 9 + 10) / 3 = 9.67
# é¢‘æ¬¡æƒé‡ï¼šmin(3, 10) Ã— 10 = 30
# çƒ­åº¦æƒé‡ï¼š3 / 3 Ã— 100 = 100
# æ€»æƒé‡ï¼š9.67 Ã— 0.6 + 30 Ã— 0.3 + 100 Ã— 0.1 = 18.8
```

**ç¤ºä¾‹ 2ï¼šæŒç»­å‡ºç°ä½†æ’åè¾ƒä½**

```python
title_data = {
    "ranks": [8, 9, 8, 7],  # æ’å7-9ï¼Œå‡ºç°4æ¬¡
    "count": 4
}

# æ’åæƒé‡ï¼š(3 + 2 + 3 + 4) / 4 = 3.0
# é¢‘æ¬¡æƒé‡ï¼šmin(4, 10) Ã— 10 = 40
# çƒ­åº¦æƒé‡ï¼š0 / 4 Ã— 100 = 0ï¼ˆæ²¡æœ‰é«˜æ’åï¼‰
# æ€»æƒé‡ï¼š3.0 Ã— 0.6 + 40 Ã— 0.3 + 0 Ã— 0.1 = 13.8
```

### 4. æ’åºé€»è¾‘

```python
# æŒ‰æƒé‡é™åºæ’åº
sorted_titles = sorted(
    all_titles,
    key=lambda x: (
        -calculate_news_weight(x, rank_threshold),  # æƒé‡é™åº
        min(x["ranks"]) if x["ranks"] else 999,    # æœ€ä½³æ’åå‡åºï¼ˆæ¬¡è¦ï¼‰
        -x["count"],                                # å‡ºç°æ¬¡æ•°é™åºï¼ˆå†æ¬¡è¦ï¼‰
    ),
)
```

**æ’åºä¼˜å…ˆçº§**ï¼š
1. **æƒé‡åˆ†æ•°**ï¼ˆä¸»è¦ï¼‰
2. **æœ€ä½³æ’å**ï¼ˆæ¬¡è¦ï¼Œæƒé‡ç›¸åŒæ—¶ï¼‰
3. **å‡ºç°æ¬¡æ•°**ï¼ˆå†æ¬¡è¦ï¼‰

---

## ğŸ“Š æ¨é€æ¨¡å¼é€»è¾‘

### 1. dailyï¼ˆå½“æ—¥æ±‡æ€»æ¨¡å¼ï¼‰

**ç‰¹ç‚¹**ï¼šæŒ‰æ—¶æ¨é€å½“æ—¥æ‰€æœ‰åŒ¹é…æ–°é—»

**é€»è¾‘**ï¼š
```python
if mode == "daily":
    # 1. åŠ è½½å½“å¤©æ‰€æœ‰å†å²æ•°æ®
    all_today_data = read_all_today_titles()
    
    # 2. ç»Ÿè®¡æ‰€æœ‰åŒ¹é…çš„æ–°é—»ï¼ˆåŒ…æ‹¬ä¹‹å‰æ¨é€è¿‡çš„ï¼‰
    stats = count_word_frequency(
        all_today_data,  # ä½¿ç”¨å®Œæ•´å†å²æ•°æ®
        word_groups,
        mode="daily"
    )
    
    # 3. ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    report = generate_summary_report(stats, new_titles)
    
    # 4. å‘é€é€šçŸ¥
    send_notification(report)
```

**æ¨é€æ—¶æœº**ï¼šæ¯æ¬¡ GitHub Actions æ‰§è¡Œæ—¶éƒ½æ¨é€

**å†…å®¹**ï¼šå½“æ—¥æ‰€æœ‰åŒ¹é…æ–°é—» + æ–°å¢æ–°é—»åŒºåŸŸ

### 2. incrementalï¼ˆå¢é‡ç›‘æ§æ¨¡å¼ï¼‰

**ç‰¹ç‚¹**ï¼šåªæ¨é€æ–°å¢å†…å®¹ï¼Œé›¶é‡å¤

**é€»è¾‘**ï¼š
```python
if mode == "incremental":
    # 1. æ£€æµ‹æ–°å¢æ–°é—»
    new_titles = detect_latest_new_titles()
    
    # 2. åªå¤„ç†æ–°å¢çš„æ–°é—»
    if new_titles:
        # åªç»Ÿè®¡æ–°å¢æ–°é—»ä¸­åŒ¹é…å…³é”®è¯çš„
        stats = count_word_frequency(
            new_titles,  # åªä½¿ç”¨æ–°å¢æ•°æ®
            word_groups,
            mode="incremental"
        )
        
        # 3. ç”ŸæˆæŠ¥å‘Š
        report = generate_incremental_report(stats)
        
        # 4. å‘é€é€šçŸ¥
        send_notification(report)
    else:
        print("å¢é‡æ¨¡å¼ï¼šæœªæ£€æµ‹åˆ°æ–°å¢æ–°é—»ï¼Œä¸æ¨é€")
```

**æ¨é€æ—¶æœº**ï¼šåªæœ‰æ–°å‡ºç°åŒ¹é…å…³é”®è¯çš„æ–°é—»æ—¶æ‰æ¨é€

**å†…å®¹**ï¼šä»…æ–°å¢çš„åŒ¹é…æ–°é—»

### 3. currentï¼ˆå½“å‰æ¦œå•æ¨¡å¼ï¼‰

**ç‰¹ç‚¹**ï¼šæŒ‰æ—¶æ¨é€å½“å‰æ¦œå•åŒ¹é…æ–°é—»

**é€»è¾‘**ï¼š
```python
if mode == "current":
    # 1. åŠ è½½å®Œæ•´å†å²æ•°æ®ï¼ˆç”¨äºç»Ÿè®¡ä¿¡æ¯ï¼‰
    all_today_data = read_all_today_titles()
    
    # 2. ä½†åªç»Ÿè®¡æœ€æ–°ä¸€æ¬¡çˆ¬å–çš„æ•°æ®
    latest_data = get_latest_crawl_results()
    
    # 3. ç»Ÿè®¡å½“å‰æ¦œå•åŒ¹é…çš„æ–°é—»
    stats = count_word_frequency(
        latest_data,  # åªä½¿ç”¨æœ€æ–°æ•°æ®
        word_groups,
        mode="current"
    )
    
    # 4. ç”ŸæˆæŠ¥å‘Šï¼ˆåŒ…å«å†å²ç»Ÿè®¡ä¿¡æ¯ï¼‰
    report = generate_current_report(stats, all_today_data)
    
    # 5. å‘é€é€šçŸ¥
    send_notification(report)
```

**æ¨é€æ—¶æœº**ï¼šæ¯æ¬¡ GitHub Actions æ‰§è¡Œæ—¶éƒ½æ¨é€

**å†…å®¹**ï¼šå½“å‰æ¦œå•åŒ¹é…æ–°é—» + æ–°å¢æ–°é—»åŒºåŸŸ + å†å²ç»Ÿè®¡ä¿¡æ¯

---

## ğŸ’¾ æ•°æ®å­˜å‚¨æœºåˆ¶

### 1. æ–‡ä»¶ç»“æ„

```
output/
â””â”€â”€ 2025å¹´11æœˆ22æ—¥/
    â”œâ”€â”€ txt/
    â”‚   â”œâ”€â”€ 08æ—¶00åˆ†.txt
    â”‚   â”œâ”€â”€ 10æ—¶00åˆ†.txt
    â”‚   â”œâ”€â”€ 12æ—¶00åˆ†.txt
    â”‚   â””â”€â”€ ...
    â””â”€â”€ html/
        â”œâ”€â”€ 08æ—¶00åˆ†.html
        â”œâ”€â”€ 10æ—¶00åˆ†.html
        â”œâ”€â”€ å½“æ—¥æ±‡æ€».html
        â””â”€â”€ ...
```

### 2. TXT æ–‡ä»¶æ ¼å¼

```
zhihu | çŸ¥ä¹
1. æ–°é—»æ ‡é¢˜1
2. æ–°é—»æ ‡é¢˜2
...

weibo | å¾®åš
1. æ–°é—»æ ‡é¢˜1
2. æ–°é—»æ ‡é¢˜2
...
```

**ç”¨é€”**ï¼š
- å†å²æ•°æ®å­˜å‚¨
- å¢é‡æ£€æµ‹
- è¶‹åŠ¿åˆ†æ

### 3. HTML æ–‡ä»¶æ ¼å¼

**å®æ—¶æŠ¥å‘Š**ï¼š`HHæ—¶MMåˆ†.html`
- åŒ…å«å½“å‰çˆ¬å–çš„æ•°æ®
- æŒ‰æƒé‡æ’åº
- åŒ…å«æ’åã€æ—¶é—´ã€é“¾æ¥ç­‰ä¿¡æ¯

**æ±‡æ€»æŠ¥å‘Š**ï¼š`å½“æ—¥æ±‡æ€».html`
- åŒ…å«å½“å¤©æ‰€æœ‰æ•°æ®
- æŒ‰è¯ç»„åˆ†ç±»
- åŒ…å«æ–°å¢æ–°é—»åŒºåŸŸ

### 4. æ•°æ®è¯»å–

**å‡½æ•°**ï¼š`read_all_today_titles()`

**é€»è¾‘**ï¼š
```python
def read_all_today_titles(platform_ids=None):
    # 1. è·å–å½“å¤©æ—¥æœŸ
    today = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
    
    # 2. è¯»å–å½“å¤©æ‰€æœ‰ TXT æ–‡ä»¶
    txt_dir = f"output/{today}/txt/"
    all_results = {}
    title_info = {}  # è®°å½•æ¯ä¸ªæ ‡é¢˜çš„æ—¶é—´ä¿¡æ¯
    
    for file_path in glob.glob(f"{txt_dir}/*.txt"):
        # 3. è§£ææ–‡ä»¶åè·å–æ—¶é—´
        time_str = extract_time_from_filename(file_path)
        
        # 4. è§£ææ–‡ä»¶å†…å®¹
        platform_data = parse_txt_file(file_path)
        
        # 5. åˆå¹¶æ•°æ®
        for platform_id, titles in platform_data.items():
            if platform_ids and platform_id not in platform_ids:
                continue  # è¿‡æ»¤å¹³å°
            
            if platform_id not in all_results:
                all_results[platform_id] = {}
            
            for title, info in titles.items():
                if title not in all_results[platform_id]:
                    all_results[platform_id][title] = {
                        "ranks": [],
                        "url": info.get("url"),
                        "first_time": time_str,
                        "last_time": time_str,
                    }
                
                # åˆå¹¶æ’å
                all_results[platform_id][title]["ranks"].extend(info["ranks"])
                
                # æ›´æ–°æ—¶é—´èŒƒå›´
                if time_str < all_results[platform_id][title]["first_time"]:
                    all_results[platform_id][title]["first_time"] = time_str
                if time_str > all_results[platform_id][title]["last_time"]:
                    all_results[platform_id][title]["last_time"] = time_str
    
    return all_results, id_to_name, title_info
```

---

## ğŸ”„ å®Œæ•´æ‰§è¡Œæµç¨‹

### æµç¨‹å›¾

```
1. GitHub Actions è§¦å‘
   â”‚
   â–¼
2. NewsAnalyzer.run()
   â”‚
   â”œâ”€â–º åŠ è½½é…ç½® (config.yaml, frequency_words.txt)
   â”‚
   â”œâ”€â–º æ£€æŸ¥é€šçŸ¥æ¸ é“é…ç½®
   â”‚
   â””â”€â–º è·å–æ¨é€æ¨¡å¼ç­–ç•¥
       â”‚
       â–¼
3. _crawl_data()
   â”‚
   â”œâ”€â–º è¯»å–å¹³å°é…ç½®
   â”‚
   â”œâ”€â–º DataFetcher.crawl_websites()
   â”‚   â”‚
   â”‚   â”œâ”€â–º éå†æ¯ä¸ªå¹³å°
   â”‚   â”‚   â”‚
   â”‚   â”‚   â”œâ”€â–º fetch_data() - è¯·æ±‚ API
   â”‚   â”‚   â”‚   â”œâ”€â–º æ„å»º URL
   â”‚   â”‚   â”‚   â”œâ”€â–º å‘é€ HTTP è¯·æ±‚
   â”‚   â”‚   â”‚   â”œâ”€â–º è§£æ JSON å“åº”
   â”‚   â”‚   â”‚   â””â”€â–º é‡è¯•æœºåˆ¶ï¼ˆå¤±è´¥æ—¶ï¼‰
   â”‚   â”‚   â”‚
   â”‚   â”‚   â””â”€â–º è¯·æ±‚é—´éš”æ§åˆ¶ï¼ˆ1ç§’ + éšæœºæ³¢åŠ¨ï¼‰
   â”‚   â”‚
   â”‚   â””â”€â–º è§£ææ•°æ®ï¼Œæå–æ ‡é¢˜ã€æ’åã€é“¾æ¥
   â”‚
   â””â”€â–º save_titles_to_file() - ä¿å­˜åŸå§‹æ•°æ®
       â”‚
       â–¼
4. _execute_mode_strategy()
   â”‚
   â”œâ”€â–º detect_latest_new_titles() - æ£€æµ‹æ–°å¢æ–°é—»
   â”‚
   â”œâ”€â–º load_frequency_words() - åŠ è½½å…³é”®è¯
   â”‚
   â”œâ”€â–º count_word_frequency() - ç»Ÿè®¡åŒ¹é…æ–°é—»
   â”‚   â”‚
   â”‚   â”œâ”€â–º éå†æ‰€æœ‰æ–°é—»
   â”‚   â”‚
   â”‚   â”œâ”€â–º matches_word_groups() - å…³é”®è¯åŒ¹é…
   â”‚   â”‚   â”œâ”€â–º è¿‡æ»¤è¯æ£€æŸ¥
   â”‚   â”‚   â”œâ”€â–º å¿…é¡»è¯æ£€æŸ¥
   â”‚   â”‚   â””â”€â–º æ™®é€šè¯æ£€æŸ¥
   â”‚   â”‚
   â”‚   â”œâ”€â–º calculate_news_weight() - è®¡ç®—æƒé‡
   â”‚   â”‚   â”œâ”€â–º æ’åæƒé‡ï¼ˆ60%ï¼‰
   â”‚   â”‚   â”œâ”€â–º é¢‘æ¬¡æƒé‡ï¼ˆ30%ï¼‰
   â”‚   â”‚   â””â”€â–º çƒ­åº¦æƒé‡ï¼ˆ10%ï¼‰
   â”‚   â”‚
   â”‚   â””â”€â–º æŒ‰æƒé‡æ’åº
   â”‚
   â”œâ”€â–º prepare_report_data() - å‡†å¤‡æŠ¥å‘Šæ•°æ®
   â”‚
   â”œâ”€â–º generate_html_report() - ç”Ÿæˆ HTML æŠ¥å‘Š
   â”‚
   â””â”€â–º send_notification() - å‘é€é€šçŸ¥
       â”‚
       â”œâ”€â–º é’‰é’‰æ¨é€
       â”œâ”€â–º é£ä¹¦æ¨é€
       â”œâ”€â–º ä¼ä¸šå¾®ä¿¡æ¨é€
       â”œâ”€â–º Telegram æ¨é€
       â”œâ”€â–º é‚®ä»¶æ¨é€
       â””â”€â–º ntfy æ¨é€
```

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### 1. è¯·æ±‚ä¼˜åŒ–

- **è¯·æ±‚é—´éš”**ï¼šé»˜è®¤ 1 ç§’ï¼Œé¿å…è¿‡äºé¢‘ç¹
- **éšæœºæ³¢åŠ¨**ï¼š-10ms åˆ° +20msï¼Œæ¨¡æ‹Ÿäººç±»è¡Œä¸º
- **è¶…æ—¶è®¾ç½®**ï¼š10 ç§’è¶…æ—¶ï¼Œé¿å…é•¿æ—¶é—´ç­‰å¾…
- **é‡è¯•æœºåˆ¶**ï¼šå¤±è´¥è‡ªåŠ¨é‡è¯• 2 æ¬¡

### 2. æ•°æ®å¤„ç†ä¼˜åŒ–

- **å¢é‡æ£€æµ‹**ï¼šåªå¯¹æ¯”æ–°å¢æ•°æ®ï¼Œä¸é‡å¤å¤„ç†
- **ç¼“å­˜æœºåˆ¶**ï¼šMCP æœåŠ¡ä½¿ç”¨ 15 åˆ†é’Ÿç¼“å­˜
- **æ–‡ä»¶è¯»å–**ï¼šæŒ‰éœ€è¯»å–ï¼Œä¸ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®

### 3. å†…å­˜ä¼˜åŒ–

- **æµå¼å¤„ç†**ï¼šé€ä¸ªå¹³å°å¤„ç†ï¼Œä¸ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®
- **åŠæ—¶é‡Šæ”¾**ï¼šå¤„ç†å®Œçš„æ•°æ®åŠæ—¶é‡Šæ”¾å†…å­˜

---

## ğŸ” å…³é”®ä»£ç ä½ç½®

| åŠŸèƒ½ | æ–‡ä»¶ | å‡½æ•°/ç±» |
|------|------|--------|
| æ•°æ®è·å– | `main.py` | `DataFetcher.fetch_data()` |
| æ‰¹é‡çˆ¬å– | `main.py` | `DataFetcher.crawl_websites()` |
| å…³é”®è¯åŒ¹é… | `main.py` | `matches_word_groups()` |
| æƒé‡è®¡ç®— | `main.py` | `calculate_news_weight()` |
| æ–°å¢æ£€æµ‹ | `main.py` | `detect_latest_new_titles()` |
| ç»Ÿè®¡é¢‘ç‡ | `main.py` | `count_word_frequency()` |
| æŠ¥å‘Šç”Ÿæˆ | `main.py` | `generate_html_report()` |
| ä¸»æµç¨‹ | `main.py` | `NewsAnalyzer.run()` |

---

## ğŸ¯ æ€»ç»“

TrendRadar çš„æ–°é—»çƒ­ç‚¹çˆ¬å–é€»è¾‘æ˜¯ä¸€ä¸ª**å¤šé˜¶æ®µã€æ™ºèƒ½åŒ–çš„æ•°æ®å¤„ç†æµç¨‹**ï¼š

1. **æ•°æ®è·å–**ï¼šé€šè¿‡ç»Ÿä¸€ API è·å–å¤šå¹³å°çƒ­ç‚¹æ•°æ®
2. **æ•°æ®å­˜å‚¨**ï¼šä¿å­˜åŸå§‹æ•°æ®ï¼Œæ”¯æŒå†å²è¿½æº¯
3. **æ™ºèƒ½ç­›é€‰**ï¼šé€šè¿‡å…³é”®è¯åŒ¹é…ï¼Œåªå…³æ³¨ç›¸å…³å†…å®¹
4. **æƒé‡æ’åº**ï¼šç»¼åˆè€ƒè™‘æ’åã€é¢‘æ¬¡ã€çƒ­åº¦ï¼Œé‡æ–°æ’åº
5. **æ¨¡å¼æ¨é€**ï¼šæ ¹æ®ç”¨æˆ·éœ€æ±‚ï¼Œé€‰æ‹©ä¸åŒçš„æ¨é€ç­–ç•¥

æ•´ä¸ªç³»ç»Ÿè®¾è®¡**è½»é‡ã€é«˜æ•ˆã€å¯æ‰©å±•**ï¼Œèƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·ä»æµ·é‡ä¿¡æ¯ä¸­ç²¾å‡†è·å–å…³å¿ƒçš„çƒ­ç‚¹æ–°é—»ã€‚

